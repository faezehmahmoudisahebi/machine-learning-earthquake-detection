{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\mahmoudi\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import obspy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from obspy.imaging.cm import obspy_sequential\n",
    "from obspy.signal.tf_misfit import cwt\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import png\n",
    "import scipy\n",
    "import sys  \n",
    "from scipy import signal\n",
    "from scipy import pi\n",
    "from scipy.io.wavfile import write\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np    \n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "#from scipy.fft import fftshift\n",
    "from scipy import signal\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from pathlib import Path\n",
    "import os, shutil\n",
    "from PIL import Image\n",
    "import pywt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the directory where the original\n",
    "# dataset was uncompressed\n",
    "# positive_dataset_dir = r\"C:\\Users\\Geopersian\\Documents\\eart_quake\\positive\"\n",
    "# negative_dataset_dir = r\"C:\\Users\\Geopersian\\Documents\\eart_quake\\negative\"\n",
    "\n",
    "# # The directory where we will\n",
    "# # store our smaller dataset\n",
    "# if os.path.exists(r\"C:\\Users\\Geopersian\\Documents\\data_earthquake\"):\n",
    "#     os.remove(r\"C:\\Users\\Geopersian\\Documents\\data_earthquake\")\n",
    "# else:\n",
    "#     base_dir = (r\"C:\\Users\\Geopersian\\Documents\\data_earthquake\")\n",
    "#     os.mkdir(base_dir)\n",
    "\n",
    "base_dir = \"D:\\Data\\data_earthquake\"\n",
    "data_dir = \"earthquake\"\n",
    "negative_dataset_dir= os.path.join(base_dir , 'negative')\n",
    "positive_dataset_dir = os.path.join(base_dir , 'positive')\n",
    "data_dir = os.path.join(base_dir , data_dir)\n",
    "\n",
    "if os.path.exists(data_dir):\n",
    "    shutil.rmtree(data_dir)\n",
    "else:\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Directories for our training,\n",
    "# validation and test splits\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir)\n",
    "else:\n",
    "    os.makedirs(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(data_dir, 'validation')\n",
    "if os.path.exists(validation_dir):\n",
    "    shutil.rmtree(validation_dir)\n",
    "else:\n",
    "    os.makedirs(validation_dir)\n",
    "\n",
    "\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "if os.path.exists(test_dir):\n",
    "    shutil.rmtree(test_dir)\n",
    "else:\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "\n",
    "# Directory with our training cat pictures\n",
    "train_positive_dir = os.path.join(train_dir, 'Positive')\n",
    "os.mkdir(train_positive_dir)\n",
    "\n",
    "# Directory with our training dog pictures\n",
    "train_negative_dir = os.path.join(train_dir, 'negative')\n",
    "os.mkdir(train_negative_dir)\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'Positive')\n",
    "os.mkdir(validation_cats_dir)\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'negetive')\n",
    "os.mkdir(validation_dogs_dir)\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "test_positive_dir = os.path.join(test_dir, 'Positive')\n",
    "os.mkdir(test_positive_dir)\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "test_negative_dir = os.path.join(test_dir, 'negative')\n",
    "os.mkdir(test_negative_dir)\n",
    "\n",
    "# Copy first 1000 cat images to train_cats_dir\n",
    "fnames = ['plot{}.png'.format(i) for i in range(80)]\n",
    "size=(224,224)\n",
    "for fname in fnames:\n",
    "    src = os.path.join(positive_dataset_dir, fname)\n",
    "    dst = os.path.join(train_positive_dir, fname)\n",
    "    img=cv2.imread(src)\n",
    "    img_resize=cv2.resize(img,size,interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite(dst,img_resize)\n",
    "\n",
    "# Copy next 500 cat images to validation_cats_dir\n",
    "fnames = ['plot{}.png'.format(i) for i in range(80, 132)]\n",
    "size=(224,224)\n",
    "for fname in fnames:\n",
    "    src = os.path.join(positive_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    img=cv2.imread(src)\n",
    "    img_resize=cv2.resize(img,size,interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite(dst,img_resize)\n",
    "    \n",
    "# Copy next 500 cat images to test_cats_dir\n",
    "fnames = ['plot{}.png'.format(i) for i in range(132, 188)]\n",
    "size=(224,224)\n",
    "for fname in fnames:\n",
    "    src = os.path.join(positive_dataset_dir, fname)\n",
    "    dst = os.path.join(test_positive_dir, fname)\n",
    "    img=cv2.imread(src)\n",
    "    img_resize=cv2.resize(img,size,interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite(dst,img_resize)\n",
    "    \n",
    "# # Copy first 1000 dog images to train_dogs_dir\n",
    "fnames = ['plot{}.png'.format(i) for i in range(61)]\n",
    "size=(224,224)\n",
    "for fname in fnames:\n",
    "    src = os.path.join(negative_dataset_dir, fname)\n",
    "    dst = os.path.join(train_negative_dir, fname)\n",
    "    img=cv2.imread(src)\n",
    "    img_resize=cv2.resize(img,size,interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite(dst,img_resize)\n",
    "    \n",
    "# # Copy next 500 dog images to validation_dogs_dir\n",
    "fnames = ['plot{}.png'.format(i) for i in range(61, 101)]\n",
    "size=(224,224)\n",
    "for fname in fnames:\n",
    "    src = os.path.join(negative_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    img=cv2.imread(src)\n",
    "    img_resize=cv2.resize(img,size,interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite(dst,img_resize)\n",
    "    \n",
    "    \n",
    "# # Copy next 500 dog images to test_dogs_dir\n",
    "fnames = ['plot{}.png'.format(i) for i in range(101, 141)]\n",
    "size=(224,224)\n",
    "for fname in fnames:\n",
    "    src = os.path.join(negative_dataset_dir, fname)\n",
    "    dst = os.path.join(test_negative_dir, fname)\n",
    "    img=cv2.imread(src)\n",
    "    img_resize=cv2.resize(img,size,interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite(dst,img_resize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Dropout,Dense\n",
    "# feature_maps =ResNet50(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3)) \n",
    "# model = keras.models.Sequential()\n",
    "# feature_maps.trainable = False\n",
    "# model.add(feature_maps)\n",
    "# # model.add(keras.layers.MaxPool2D((7, 7)))\n",
    "# model.add(keras.layers.Flatten())\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 141 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models \n",
    "image_gen_train = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=45,\n",
    "                    width_shift_range=.15,\n",
    "                    height_shift_range=.15,\n",
    "                    horizontal_flip=True,\n",
    "                    zoom_range=0.5\n",
    "                    )\n",
    "\n",
    "\n",
    "train_data_gen = image_gen_train.flow_from_directory(\n",
    "                                                batch_size=3,\n",
    "                                                directory=train_dir,\n",
    "                                                shuffle=True,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='sparse'\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 92 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models \n",
    "image_gen_validation = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=45,\n",
    "                    width_shift_range=.15,\n",
    "                    height_shift_range=.15,\n",
    "                    horizontal_flip=True,\n",
    "                    zoom_range=0.5\n",
    "                    )\n",
    "\n",
    "\n",
    "validation_data_gen = image_gen_train.flow_from_directory(\n",
    "                                                batch_size=3,\n",
    "                                                directory=validation_dir,\n",
    "                                                shuffle=True,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='sparse'\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 141 files belonging to 2 classes.\n",
      "Found 92 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models \n",
    "width_shift = 3/32\n",
    "height_shift = 3/32\n",
    "flip = True\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory( \n",
    "directory=r\"D:\\Data\\data_earthquake\\earthquake\\train\", \n",
    "labels='inferred',\n",
    "label_mode='categorical', \n",
    "batch_size=32, \n",
    "image_size=(224, 224),\n",
    ") \n",
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory( \n",
    "directory=r\"D:\\Data\\data_earthquake\\earthquake\\validation\", \n",
    "labels='inferred', \n",
    "label_mode='categorical',\n",
    "batch_size=32, \n",
    "image_size=(224, 224),\n",
    ")\n",
    "\n",
    "# model = tf.keras.applications.resnet50.ResNet50(\n",
    "# weights=None, input_shape=(224, 224, 3), classes=2)\n",
    "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "# model.fit(train_ds, epochs=10, validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 128)     3584      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 222, 222, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 128)     147584    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 109, 109, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 373248)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 373248)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               37324900  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 37,476,169\n",
      "Trainable params: 37,476,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Activation,Dropout\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "\n",
    "# Conv1\n",
    "model.add(Conv2D(128, (3,3), input_shape=(224, 224, 3)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "# Conv2\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(100, activation='sigmoid'))\n",
    "\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same',))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same',))\n",
    "    model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same',))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same',))\n",
    "    model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# model.save \n",
    "# model=load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 90s 2s/step - loss: 2.0558 - accuracy: 0.5603 - val_loss: 1.6664 - val_accuracy: 0.5652\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 91s 2s/step - loss: 1.3062 - accuracy: 0.5674 - val_loss: 0.9905 - val_accuracy: 0.5652\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 98s 2s/step - loss: 0.8212 - accuracy: 0.5674 - val_loss: 0.7153 - val_accuracy: 0.5652\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 118s 2s/step - loss: 0.6994 - accuracy: 0.5674 - val_loss: 0.6883 - val_accuracy: 0.5652\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 114s 2s/step - loss: 0.6897 - accuracy: 0.5674 - val_loss: 0.6854 - val_accuracy: 0.5652\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 118s 2s/step - loss: 0.6906 - accuracy: 0.5674 - val_loss: 0.6865 - val_accuracy: 0.5652\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 142s 3s/step - loss: 0.6897 - accuracy: 0.5674 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 102s 2s/step - loss: 0.6880 - accuracy: 0.5674 - val_loss: 0.6871 - val_accuracy: 0.5652\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 141s 3s/step - loss: 0.6908 - accuracy: 0.5674 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 147s 3s/step - loss: 0.6851 - accuracy: 0.5674 - val_loss: 0.6893 - val_accuracy: 0.5652\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 142s 3s/step - loss: 0.6910 - accuracy: 0.5461 - val_loss: 0.6847 - val_accuracy: 0.5652\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 159s 3s/step - loss: 0.6898 - accuracy: 0.5674 - val_loss: 0.6850 - val_accuracy: 0.5652\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 136s 3s/step - loss: 0.6908 - accuracy: 0.5674 - val_loss: 0.6849 - val_accuracy: 0.5652\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 142s 3s/step - loss: 0.6897 - accuracy: 0.5674 - val_loss: 0.6850 - val_accuracy: 0.5652\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.6879 - accuracy: 0.5248 - val_loss: 0.6871 - val_accuracy: 0.5652\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 143s 3s/step - loss: 0.6885 - accuracy: 0.5674 - val_loss: 0.6849 - val_accuracy: 0.5652\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 120s 3s/step - loss: 0.6909 - accuracy: 0.5674 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 121s 3s/step - loss: 0.6911 - accuracy: 0.5674 - val_loss: 0.6864 - val_accuracy: 0.5652\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 152s 3s/step - loss: 0.6907 - accuracy: 0.5674 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.6898 - accuracy: 0.5674 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 122s 3s/step - loss: 0.6891 - accuracy: 0.5674 - val_loss: 0.6849 - val_accuracy: 0.5652\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 153s 3s/step - loss: 0.6912 - accuracy: 0.5674 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 118s 3s/step - loss: 0.6896 - accuracy: 0.5674 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 143s 3s/step - loss: 0.6890 - accuracy: 0.5603 - val_loss: 0.6867 - val_accuracy: 0.5652\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 136s 3s/step - loss: 0.6905 - accuracy: 0.5674 - val_loss: 0.6852 - val_accuracy: 0.5652\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 119s 3s/step - loss: 0.6883 - accuracy: 0.4965 - val_loss: 0.6873 - val_accuracy: 0.5652\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 139s 3s/step - loss: 0.6898 - accuracy: 0.5674 - val_loss: 0.6848 - val_accuracy: 0.5652\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 149s 3s/step - loss: 0.6897 - accuracy: 0.5674 - val_loss: 0.6850 - val_accuracy: 0.5652\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 100s 2s/step - loss: 0.6881 - accuracy: 0.5674 - val_loss: 0.6854 - val_accuracy: 0.5652\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 127s 3s/step - loss: 0.6900 - accuracy: 0.5461 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 133s 3s/step - loss: 0.6893 - accuracy: 0.5674 - val_loss: 0.6850 - val_accuracy: 0.5652\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 129s 3s/step - loss: 0.6881 - accuracy: 0.5603 - val_loss: 0.6868 - val_accuracy: 0.5652\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 136s 3s/step - loss: 0.6896 - accuracy: 0.5674 - val_loss: 0.6847 - val_accuracy: 0.5652\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 143s 3s/step - loss: 0.6894 - accuracy: 0.5674 - val_loss: 0.6860 - val_accuracy: 0.5652\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 134s 3s/step - loss: 0.6881 - accuracy: 0.5674 - val_loss: 0.6851 - val_accuracy: 0.5652\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 131s 3s/step - loss: 0.6907 - accuracy: 0.5674 - val_loss: 0.6849 - val_accuracy: 0.5652\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 179s 4s/step - loss: 0.6893 - accuracy: 0.5674 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 98s 2s/step - loss: 0.6896 - accuracy: 0.5674 - val_loss: 0.6847 - val_accuracy: 0.5652\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 145s 3s/step - loss: 0.6895 - accuracy: 0.5674 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 121s 3s/step - loss: 0.6891 - accuracy: 0.5674 - val_loss: 0.6876 - val_accuracy: 0.5652\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 134s 3s/step - loss: 0.6916 - accuracy: 0.5674 - val_loss: 0.6856 - val_accuracy: 0.5652\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 135s 3s/step - loss: 0.6884 - accuracy: 0.5532 - val_loss: 0.6866 - val_accuracy: 0.5652\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 131s 3s/step - loss: 0.6921 - accuracy: 0.5674 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 147s 3s/step - loss: 0.6905 - accuracy: 0.5674 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.6874 - accuracy: 0.5532 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 129s 3s/step - loss: 0.6890 - accuracy: 0.5674 - val_loss: 0.6857 - val_accuracy: 0.5652\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 143s 3s/step - loss: 0.6906 - accuracy: 0.5674 - val_loss: 0.6847 - val_accuracy: 0.5652\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 148s 3s/step - loss: 0.6896 - accuracy: 0.5674 - val_loss: 0.6848 - val_accuracy: 0.5652\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 110s 2s/step - loss: 0.6878 - accuracy: 0.5674 - val_loss: 0.6858 - val_accuracy: 0.5652\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 157s 3s/step - loss: 0.6894 - accuracy: 0.5674 - val_loss: 0.6847 - val_accuracy: 0.5652\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 107s 2s/step - loss: 0.6922 - accuracy: 0.5674 - val_loss: 0.6849 - val_accuracy: 0.5652\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 167s 4s/step - loss: 0.6894 - accuracy: 0.5674 - val_loss: 0.6852 - val_accuracy: 0.5652\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 127s 3s/step - loss: 0.6880 - accuracy: 0.5603 - val_loss: 0.6849 - val_accuracy: 0.5652\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 153s 3s/step - loss: 0.6897 - accuracy: 0.5674 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 160s 3s/step - loss: 0.6907 - accuracy: 0.5674 - val_loss: 0.6851 - val_accuracy: 0.5652\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 137s 3s/step - loss: 0.6878 - accuracy: 0.5674 - val_loss: 0.6847 - val_accuracy: 0.5652\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 135s 3s/step - loss: 0.6887 - accuracy: 0.5461 - val_loss: 0.6871 - val_accuracy: 0.5652\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 147s 3s/step - loss: 0.6873 - accuracy: 0.5674 - val_loss: 0.6872 - val_accuracy: 0.5652\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 139s 3s/step - loss: 0.6925 - accuracy: 0.5674 - val_loss: 0.6849 - val_accuracy: 0.5652\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 130s 3s/step - loss: 0.6899 - accuracy: 0.5674 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 240s 5s/step - loss: 0.6895 - accuracy: 0.5674 - val_loss: 0.6851 - val_accuracy: 0.5652\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 159s 3s/step - loss: 0.6899 - accuracy: 0.5603 - val_loss: 0.6847 - val_accuracy: 0.5652\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 181s 4s/step - loss: 0.6900 - accuracy: 0.5674 - val_loss: 0.6849 - val_accuracy: 0.5652\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 180s 4s/step - loss: 0.6901 - accuracy: 0.5674 - val_loss: 0.6853 - val_accuracy: 0.5652\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 182s 4s/step - loss: 0.6905 - accuracy: 0.5674 - val_loss: 0.6849 - val_accuracy: 0.5652\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 181s 4s/step - loss: 0.6891 - accuracy: 0.5674 - val_loss: 0.6865 - val_accuracy: 0.5652\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 148s 3s/step - loss: 0.6896 - accuracy: 0.5674 - val_loss: 0.6858 - val_accuracy: 0.5652\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 155s 3s/step - loss: 0.6894 - accuracy: 0.5674 - val_loss: 0.6869 - val_accuracy: 0.5652\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 145s 3s/step - loss: 0.6906 - accuracy: 0.5674 - val_loss: 0.6851 - val_accuracy: 0.5652\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 119s 3s/step - loss: 0.6914 - accuracy: 0.5674 - val_loss: 0.6847 - val_accuracy: 0.5652\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 179s 4s/step - loss: 0.6911 - accuracy: 0.5674 - val_loss: 0.6855 - val_accuracy: 0.5652\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 129s 3s/step - loss: 0.6874 - accuracy: 0.5674 - val_loss: 0.6852 - val_accuracy: 0.5652\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 520s 11s/step - loss: 0.6912 - accuracy: 0.5674 - val_loss: 0.6850 - val_accuracy: 0.5652\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6887 - accuracy: 0.5674 - val_loss: 0.6863 - val_accuracy: 0.5652\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 100s 2s/step - loss: 0.6908 - accuracy: 0.5674 - val_loss: 0.6847 - val_accuracy: 0.5652\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 154s 3s/step - loss: 0.6912 - accuracy: 0.5674 - val_loss: 0.6849 - val_accuracy: 0.5652\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 171s 4s/step - loss: 0.6846 - accuracy: 0.5390 - val_loss: 0.6882 - val_accuracy: 0.5652\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 160s 3s/step - loss: 0.6933 - accuracy: 0.5674 - val_loss: 0.6862 - val_accuracy: 0.5652\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 160s 3s/step - loss: 0.6879 - accuracy: 0.5674 - val_loss: 0.6854 - val_accuracy: 0.5652\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 182s 4s/step - loss: 0.6904 - accuracy: 0.5674 - val_loss: 0.6848 - val_accuracy: 0.5652\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 200s 4s/step - loss: 0.6886 - accuracy: 0.5674 - val_loss: 0.6873 - val_accuracy: 0.5652\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 184s 4s/step - loss: 0.6870 - accuracy: 0.5674 - val_loss: 0.6861 - val_accuracy: 0.5652\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 141s 3s/step - loss: 0.6881 - accuracy: 0.5674 - val_loss: 0.6858 - val_accuracy: 0.5652\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 182s 4s/step - loss: 0.6890 - accuracy: 0.5674 - val_loss: 0.6847 - val_accuracy: 0.5652\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 132s 3s/step - loss: 0.6910 - accuracy: 0.5674 - val_loss: 0.6847 - val_accuracy: 0.5652\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 181s 4s/step - loss: 0.6896 - accuracy: 0.5674 - val_loss: 0.6863 - val_accuracy: 0.5652\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 139s 3s/step - loss: 0.6899 - accuracy: 0.5674 - val_loss: 0.6861 - val_accuracy: 0.5652\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 139s 3s/step - loss: 0.6873 - accuracy: 0.5674 - val_loss: 0.6855 - val_accuracy: 0.5652\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 158s 3s/step - loss: 0.6888 - accuracy: 0.5674 - val_loss: 0.6859 - val_accuracy: 0.5652\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 157s 3s/step - loss: 0.6862 - accuracy: 0.5674 - val_loss: 0.6866 - val_accuracy: 0.5652\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 128s 3s/step - loss: 0.6922 - accuracy: 0.5674 - val_loss: 0.6853 - val_accuracy: 0.5652\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 184s 4s/step - loss: 0.6902 - accuracy: 0.5674 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 116s 2s/step - loss: 0.6904 - accuracy: 0.5674 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 183s 4s/step - loss: 0.6907 - accuracy: 0.5674 - val_loss: 0.6847 - val_accuracy: 0.5652\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 144s 3s/step - loss: 0.6902 - accuracy: 0.5674 - val_loss: 0.6853 - val_accuracy: 0.5652\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 156s 3s/step - loss: 0.6902 - accuracy: 0.5674 - val_loss: 0.6854 - val_accuracy: 0.5652\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 157s 3s/step - loss: 0.6924 - accuracy: 0.5674 - val_loss: 0.6847 - val_accuracy: 0.5652\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 144s 3s/step - loss: 0.6892 - accuracy: 0.5674 - val_loss: 0.6853 - val_accuracy: 0.5652\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 149s 3s/step - loss: 0.6898 - accuracy: 0.5674 - val_loss: 0.6847 - val_accuracy: 0.5652\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 152s 3s/step - loss: 0.6906 - accuracy: 0.5674 - val_loss: 0.6847 - val_accuracy: 0.5652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f09e06ee10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = tf.keras.applications.resnet50.ResNet50(\n",
    "# weights=None, input_shape=(224, 224, 3), classes=2)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "model.fit(train_data_gen, epochs=100, validation_data=validation_data_gen )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(\n",
    "#     x=train_ds,\n",
    "#     batch_size=3S,\n",
    "#     sample_weight=None,\n",
    "#     steps=None,\n",
    "#     callbacks=None,\n",
    "#     max_queue_size=10,\n",
    "#     workers=1,\n",
    "#     use_multiprocessing=False,\n",
    "#     return_dict=False,\n",
    "#     **kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Haar', 'Daubechies', 'Symlets', 'Coiflets', 'Biorthogonal', 'Reverse biorthogonal', 'Discrete Meyer (FIR Approximation)', 'Gaussian', 'Mexican hat wavelet', 'Morlet wavelet', 'Complex Gaussian wavelets', 'Shannon wavelets', 'Frequency B-Spline wavelets', 'Complex Morlet wavelets']\n"
     ]
    }
   ],
   "source": [
    "print(pywt.families(short=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ca1661576c27b96fea16db0ee6e5056fc0781559f5710223513221c5c76749e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
